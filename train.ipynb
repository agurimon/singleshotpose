{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b839f32b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-06T13:20:49.462059Z",
     "start_time": "2023-01-06T13:20:47.715656Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import sys\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "import shutil\n",
    "import argparse\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable # Useful info about autograd: http://pytorch.org/docs/master/notes/autograd.html\n",
    "\n",
    "import dataset\n",
    "from utils import *    \n",
    "from cfg import parse_cfg\n",
    "from region_loss import RegionLoss\n",
    "from darknet import Darknet\n",
    "from MeshPly import MeshPly\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "591c42e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-06T13:20:50.880900Z",
     "start_time": "2023-01-06T13:20:50.875661Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create new directory\n",
    "def makedirs(path):\n",
    "    if not os.path.exists( path ):\n",
    "        os.makedirs( path )\n",
    "\n",
    "# Adjust learning rate during training, learning schedule can be changed in network config file\n",
    "def adjust_learning_rate(optimizer, batch):\n",
    "    lr = learning_rate\n",
    "    for i in range(len(steps)):\n",
    "        scale = scales[i] if i < len(scales) else 1\n",
    "        if batch >= steps[i]:\n",
    "            lr = lr * scale\n",
    "            if batch == steps[i]:\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr/batch_size\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eec10ca6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-06T13:20:52.755668Z",
     "start_time": "2023-01-06T13:20:52.742462Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "\n",
    "    global processed_batches\n",
    "    \n",
    "    # Initialize timer\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Get the dataloader for training dataset\n",
    "    train_loader = torch.utils.data.DataLoader(dataset.listDataset(trainlist, \n",
    "                                                                   shape=(init_width, init_height),\n",
    "                                                            \t   shuffle=True,\n",
    "                                                            \t   transform=transforms.Compose([transforms.ToTensor(),]), \n",
    "                                                            \t   train=True, \n",
    "                                                            \t   seen=model.seen,\n",
    "                                                            \t   batch_size=batch_size,\n",
    "                                                            \t   num_workers=num_workers, \n",
    "                                                                   bg_file_names=bg_file_names),\n",
    "                                                batch_size=batch_size, shuffle=False, **kwargs)\n",
    "\n",
    "    # TRAINING\n",
    "    lr = adjust_learning_rate(optimizer, processed_batches)\n",
    "#     logging('epoch %d, processed %d samples, lr %f' % (epoch, epoch * len(train_loader.dataset), lr))\n",
    "    # Start training\n",
    "    model.train()\n",
    "    t1 = time.time()\n",
    "    avg_time = torch.zeros(9)\n",
    "    niter = 0\n",
    "    # Iterate through batches\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        t2 = time.time()\n",
    "        # adjust learning rate\n",
    "        adjust_learning_rate(optimizer, processed_batches)\n",
    "        processed_batches = processed_batches + 1\n",
    "        # Pass the data to GPU\n",
    "        if use_cuda:\n",
    "            data = data.cuda()\n",
    "        t3 = time.time()\n",
    "        # Wrap tensors in Variable class for automatic differentiation\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        t4 = time.time()\n",
    "        # Zero the gradients before running the backward pass\n",
    "        optimizer.zero_grad()\n",
    "        t5 = time.time()\n",
    "        # Forward pass\n",
    "        output = model(data)\n",
    "        t6 = time.time()\n",
    "        model.seen = model.seen + data.data.size(0)\n",
    "        region_loss.seen = region_loss.seen + data.data.size(0)\n",
    "        # Compute loss, grow an array of losses for saving later on\n",
    "        loss = region_loss(output, target, epoch)\n",
    "        training_iters.append(epoch * math.ceil(len(train_loader.dataset) / float(batch_size) ) + niter)\n",
    "        training_losses.append(convert2cpu(loss.data))\n",
    "        niter += 1\n",
    "        t7 = time.time()\n",
    "        # Backprop: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "        t8 = time.time()\n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "        t9 = time.time()\n",
    "        # Print time statistics\n",
    "        if False and batch_idx > 1:\n",
    "            avg_time[0] = avg_time[0] + (t2-t1)\n",
    "            avg_time[1] = avg_time[1] + (t3-t2)\n",
    "            avg_time[2] = avg_time[2] + (t4-t3)\n",
    "            avg_time[3] = avg_time[3] + (t5-t4)\n",
    "            avg_time[4] = avg_time[4] + (t6-t5)\n",
    "            avg_time[5] = avg_time[5] + (t7-t6)\n",
    "            avg_time[6] = avg_time[6] + (t8-t7)\n",
    "            avg_time[7] = avg_time[7] + (t9-t8)\n",
    "            avg_time[8] = avg_time[8] + (t9-t1)\n",
    "            print('-------------------------------')\n",
    "            print('       load data : %f' % (avg_time[0]/(batch_idx)))\n",
    "            print('     cpu to cuda : %f' % (avg_time[1]/(batch_idx)))\n",
    "            print('cuda to variable : %f' % (avg_time[2]/(batch_idx)))\n",
    "            print('       zero_grad : %f' % (avg_time[3]/(batch_idx)))\n",
    "            print(' forward feature : %f' % (avg_time[4]/(batch_idx)))\n",
    "            print('    forward loss : %f' % (avg_time[5]/(batch_idx)))\n",
    "            print('        backward : %f' % (avg_time[6]/(batch_idx)))\n",
    "            print('            step : %f' % (avg_time[7]/(batch_idx)))\n",
    "            print('           total : %f' % (avg_time[8]/(batch_idx)))\n",
    "        t1 = time.time()\n",
    "    t1 = time.time()\n",
    "    return epoch * math.ceil(len(train_loader.dataset) / float(batch_size) ) + niter - 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee4dfdfb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-06T13:20:55.858899Z",
     "start_time": "2023-01-06T13:20:55.839179Z"
    }
   },
   "outputs": [],
   "source": [
    "def test(epoch, niter):\n",
    "    def truths_length(truths):\n",
    "        for i in range(50):\n",
    "            if truths[i][1] == 0:\n",
    "                return i\n",
    "\n",
    "    # Set the module in evaluation mode (turn off dropout, batch normalization etc.)        \n",
    "    model.eval()\n",
    "\n",
    "    # Parameters\n",
    "    num_classes          = model.num_classes\n",
    "    anchors              = model.anchors\n",
    "    num_anchors          = model.num_anchors\n",
    "    testtime             = True\n",
    "    testing_error_trans  = 0.0\n",
    "    testing_error_angle  = 0.0\n",
    "    testing_error_pixel  = 0.0\n",
    "    testing_samples      = 0.0\n",
    "    errs_2d              = []\n",
    "    errs_3d              = []\n",
    "    errs_trans           = []\n",
    "    errs_angle           = []\n",
    "    errs_corner2D        = []\n",
    "    logging(\"   Testing...\")\n",
    "    logging(\"   Number of test samples: %d\" % len(test_loader.dataset))\n",
    "    notpredicted = 0\n",
    "    # Iterate through test examples \n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        t1 = time.time()\n",
    "        # Pass the data to GPU\n",
    "        if use_cuda:\n",
    "            data = data.cuda()\n",
    "            target = target.cuda()\n",
    "        # Wrap tensors in Variable class, set volatile=True for inference mode and to use minimal memory during inference\n",
    "        data = Variable(data, volatile=True)\n",
    "        t2 = time.time()\n",
    "        # Formward pass\n",
    "        output = model(data).data  \n",
    "        t3 = time.time()\n",
    "        # Using confidence threshold, eliminate low-confidence predictions\n",
    "        all_boxes = get_region_boxes(output, num_classes, num_keypoints)        \n",
    "        t4 = time.time()\n",
    "        # Iterate through all batch elements\n",
    "        for box_pr, target in zip([all_boxes], [target[0]]):\n",
    "            # For each image, get all the targets (for multiple object pose estimation, there might be more than 1 target per image)\n",
    "            truths = target.view(-1, num_keypoints*2+3)\n",
    "            # Get how many objects are present in the scene\n",
    "            num_gts    = truths_length(truths)\n",
    "            # Iterate through each ground-truth object\n",
    "            for k in range(num_gts):\n",
    "                box_gt = list()\n",
    "                for j in range(1, 2*num_keypoints+1):\n",
    "                    box_gt.append(truths[k][j])\n",
    "                box_gt.extend([1.0, 1.0])\n",
    "                box_gt.append(truths[k][0])\n",
    "                   \n",
    "                # Denormalize the corner predictions \n",
    "                corners2D_gt = torch.stack(box_gt[:num_keypoints*2], dim=0).reshape(num_keypoints, 2)\n",
    "                corners2D_pr = torch.stack(box_pr[:num_keypoints*2], dim=0).reshape(num_keypoints, 2)\n",
    "                corners2D_gt[:, 0] = corners2D_gt[:, 0] * im_width\n",
    "                corners2D_gt[:, 1] = corners2D_gt[:, 1] * im_height               \n",
    "                corners2D_pr[:, 0] = corners2D_pr[:, 0] * im_width\n",
    "                corners2D_pr[:, 1] = corners2D_pr[:, 1] * im_height\n",
    "\n",
    "                # Compute corner prediction error\n",
    "                corner_norm = np.linalg.norm(corners2D_gt.cpu() - corners2D_pr, axis=1)\n",
    "                corner_dist = np.mean(corner_norm)\n",
    "                errs_corner2D.append(corner_dist)\n",
    "\n",
    "                # Compute [R|t] by pnp\n",
    "                R_gt, t_gt = pnp(np.array(np.transpose(np.concatenate((np.zeros((3, 1)), corners3D[:3, :]), axis=1)), dtype='float32'),  corners2D_gt, np.array(internal_calibration, dtype='float32'))\n",
    "                R_pr, t_pr = pnp(np.array(np.transpose(np.concatenate((np.zeros((3, 1)), corners3D[:3, :]), axis=1)), dtype='float32'),  corners2D_pr, np.array(internal_calibration, dtype='float32'))\n",
    "\n",
    "                # Compute errors\n",
    "                # Compute translation error\n",
    "                trans_dist   = np.sqrt(np.sum(np.square(t_gt - t_pr)))\n",
    "                errs_trans.append(trans_dist)\n",
    "\n",
    "                # Compute angle error\n",
    "                angle_dist   = calcAngularDistance(R_gt, R_pr)\n",
    "                errs_angle.append(angle_dist)\n",
    "\n",
    "                # Compute pixel error\n",
    "                Rt_gt        = np.concatenate((R_gt, t_gt), axis=1)\n",
    "                Rt_pr        = np.concatenate((R_pr, t_pr), axis=1)\n",
    "                proj_2d_gt   = compute_projection(vertices, Rt_gt, internal_calibration) \n",
    "                proj_2d_pred = compute_projection(vertices, Rt_pr, internal_calibration) \n",
    "                norm         = np.linalg.norm(proj_2d_gt - proj_2d_pred, axis=0)\n",
    "                pixel_dist   = np.mean(norm)\n",
    "                errs_2d.append(pixel_dist)\n",
    "\n",
    "                # Compute 3D distances\n",
    "                transform_3d_gt   = compute_transformation(vertices, Rt_gt) \n",
    "                transform_3d_pred = compute_transformation(vertices, Rt_pr)  \n",
    "                norm3d            = np.linalg.norm(transform_3d_gt - transform_3d_pred, axis=0)\n",
    "                vertex_dist       = np.mean(norm3d)    \n",
    "                errs_3d.append(vertex_dist)  \n",
    "\n",
    "                # Sum errors\n",
    "                testing_error_trans  += trans_dist\n",
    "                testing_error_angle  += angle_dist\n",
    "                testing_error_pixel  += pixel_dist\n",
    "                testing_samples      += 1\n",
    "\n",
    "        t5 = time.time()\n",
    "\n",
    "    # Compute 2D projection, 6D pose and 5cm5degree scores\n",
    "    px_threshold = 5 # 5 pixel threshold for 2D reprojection error is standard in recent sota 6D object pose estimation works \n",
    "    eps          = 1e-5\n",
    "    acc          = len(np.where(np.array(errs_2d) <= px_threshold)[0]) * 100. / (len(errs_2d)+eps)\n",
    "    acc3d        = len(np.where(np.array(errs_3d) <= vx_threshold)[0]) * 100. / (len(errs_3d)+eps)\n",
    "    acc5cm5deg   = len(np.where((np.array(errs_trans) <= 0.05) & (np.array(errs_angle) <= 5))[0]) * 100. / (len(errs_trans)+eps)\n",
    "    corner_acc   = len(np.where(np.array(errs_corner2D) <= px_threshold)[0]) * 100. / (len(errs_corner2D)+eps)\n",
    "    mean_err_2d  = np.mean(errs_2d)\n",
    "    mean_corner_err_2d = np.mean(errs_corner2D)\n",
    "    nts = float(testing_samples)\n",
    "    \n",
    "    if testtime:\n",
    "        print('-----------------------------------')\n",
    "        print('  tensor to cuda : %f' % (t2 - t1))\n",
    "        print('         predict : %f' % (t3 - t2))\n",
    "        print('get_region_boxes : %f' % (t4 - t3))\n",
    "        print('            eval : %f' % (t5 - t4))\n",
    "        print('           total : %f' % (t5 - t1))\n",
    "        print('-----------------------------------')\n",
    "\n",
    "    # Print test statistics\n",
    "    logging(\"   Mean corner error is %f\" % (mean_corner_err_2d))\n",
    "    logging('   Acc using {} px 2D Projection = {:.2f}%'.format(px_threshold, acc))\n",
    "    logging('   Acc using {} vx 3D Transformation = {:.2f}%'.format(vx_threshold, acc3d))\n",
    "    logging('   Acc using 5 cm 5 degree metric = {:.2f}%'.format(acc5cm5deg))\n",
    "    logging('   Translation error: %f, angle error: %f' % (testing_error_trans/(nts+eps), testing_error_angle/(nts+eps)) )\n",
    "\n",
    "    # Register losses and errors for saving later on\n",
    "    testing_iters.append(niter)\n",
    "    testing_errors_trans.append(testing_error_trans/(nts+eps))\n",
    "    testing_errors_angle.append(testing_error_angle/(nts+eps))\n",
    "    testing_errors_pixel.append(testing_error_pixel/(nts+eps))\n",
    "    testing_accuracies.append(acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef1a68c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-06T13:21:24.943114Z",
     "start_time": "2023-01-06T13:21:24.907282Z"
    }
   },
   "outputs": [],
   "source": [
    "datacfg             = 'cfg/duck.data'\n",
    "modelcfg            = 'cfg/yolo-pose.cfg'\n",
    "initweightfile      = 'backup/duck/init.weights'\n",
    "pretrain_num_epochs = 15\n",
    "\n",
    "# Parse configuration files\n",
    "data_options  = read_data_cfg(datacfg)\n",
    "net_options   = parse_cfg(modelcfg)[0]\n",
    "trainlist     = data_options['train']\n",
    "testlist      = data_options['valid']\n",
    "gpus          = data_options['gpus'] \n",
    "meshname      = data_options['mesh']\n",
    "num_workers   = int(data_options['num_workers'])\n",
    "backupdir     = data_options['backup']\n",
    "vx_threshold  = float(data_options['diam']) * 0.1 # threshold for the ADD metric\n",
    "if not os.path.exists(backupdir):\n",
    "    makedirs(backupdir)\n",
    "batch_size    = int(net_options['batch'])\n",
    "max_batches   = int(net_options['max_batches'])\n",
    "learning_rate = float(net_options['learning_rate'])\n",
    "momentum      = float(net_options['momentum'])\n",
    "decay         = float(net_options['decay'])\n",
    "nsamples      = file_lines(trainlist)\n",
    "batch_size    = int(net_options['batch'])\n",
    "nbatches      = nsamples / batch_size\n",
    "steps         = [float(step)*nbatches for step in net_options['steps'].split(',')]\n",
    "scales        = [float(scale) for scale in net_options['scales'].split(',')]\n",
    "bg_file_names = get_all_files('VOCdevkit/VOC2012/JPEGImages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ae21b65",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-04T14:00:46.056036Z",
     "start_time": "2023-01-04T14:00:44.160520Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train parameters\n",
    "max_epochs    = int(net_options['max_epochs'])\n",
    "num_keypoints = int(net_options['num_keypoints'])\n",
    "\n",
    "# Test parameters\n",
    "im_width    = int(data_options['width'])\n",
    "im_height   = int(data_options['height'])\n",
    "fx          = float(data_options['fx'])\n",
    "fy          = float(data_options['fy'])\n",
    "u0          = float(data_options['u0'])\n",
    "v0          = float(data_options['v0'])\n",
    "test_width  = int(net_options['test_width'])\n",
    "test_height = int(net_options['test_height'])\n",
    "\n",
    "# Specify which gpus to use\n",
    "use_cuda      = True\n",
    "seed          = int(time.time())\n",
    "torch.manual_seed(seed)\n",
    "if use_cuda:\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = gpus\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "# Specifiy the model and the loss\n",
    "model       = Darknet(modelcfg)\n",
    "region_loss = RegionLoss(num_keypoints=9, num_classes=1, anchors=[], num_anchors=1, pretrain_num_epochs=15)\n",
    "\n",
    "# Model settings\n",
    "model.load_weights_until_last(initweightfile) \n",
    "# model.print_network()\n",
    "model.seen = 0\n",
    "region_loss.iter  = model.iter\n",
    "region_loss.seen  = model.seen\n",
    "processed_batches = model.seen//batch_size\n",
    "init_width        = model.width\n",
    "init_height       = model.height\n",
    "init_epoch        = model.seen//nsamples \n",
    "\n",
    "# Variable to save\n",
    "training_iters          = []\n",
    "training_losses         = []\n",
    "testing_iters           = []\n",
    "testing_losses          = []\n",
    "testing_errors_trans    = []\n",
    "testing_errors_angle    = []\n",
    "testing_errors_pixel    = []\n",
    "testing_accuracies      = []\n",
    "\n",
    "# Get the intrinsic camerea matrix, mesh, vertices and corners of the model\n",
    "mesh                 = MeshPly(meshname)\n",
    "vertices             = np.c_[np.array(mesh.vertices), np.ones((len(mesh.vertices), 1))].transpose()\n",
    "corners3D            = get_3D_corners(vertices)\n",
    "internal_calibration = get_camera_intrinsic(u0, v0, fx, fy)\n",
    "\n",
    "\n",
    "# Specify the number of workers\n",
    "kwargs = {'num_workers': num_workers, 'pin_memory': True} if use_cuda else {}\n",
    "\n",
    "# Get the dataloader for test data\n",
    "test_loader = torch.utils.data.DataLoader(dataset.listDataset(testlist, \n",
    "                                                              shape=(test_width, test_height),\n",
    "                                                              shuffle=False,\n",
    "                                                              transform=transforms.Compose([transforms.ToTensor(),]), \n",
    "                                                              train=False),\n",
    "                                         batch_size=1, shuffle=False, **kwargs)\n",
    "\n",
    "# Pass the model to GPU\n",
    "if use_cuda:\n",
    "    model = model.cuda() # model = torch.nn.DataParallel(model, device_ids=[0]).cuda() # Multiple GPU parallelism\n",
    "\n",
    "# Get the optimizer\n",
    "params_dict = dict(model.named_parameters())\n",
    "params = []\n",
    "for key, value in params_dict.items():\n",
    "    if key.find('.bn') >= 0 or key.find('.bias') >= 0:\n",
    "        params += [{'params': [value], 'weight_decay': 0.0}]\n",
    "    else:\n",
    "        params += [{'params': [value], 'weight_decay': decay*batch_size}]\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate/batch_size, momentum=momentum, dampening=0, weight_decay=decay*batch_size)\n",
    "\n",
    "best_acc      = -sys.maxsize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63cec813",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-04T14:00:46.059684Z",
     "start_time": "2023-01-04T14:00:46.057337Z"
    }
   },
   "outputs": [],
   "source": [
    "def truths_length(truths):\n",
    "    for i in range(50):\n",
    "        if truths[i][1] == 0:\n",
    "            return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adf9695a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-04T14:30:34.344231Z",
     "start_time": "2023-01-04T14:00:46.061349Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-07 00:26:07 EPOCH: [20/500]\n",
      "2023-01-07 00:26:07    Testing...\n",
      "2023-01-07 00:26:07    Number of test samples: 1065\n",
      "-----------------------------------\n",
      "  tensor to cuda : 0.000629\n",
      "         predict : 0.004027\n",
      "get_region_boxes : 0.005959\n",
      "            eval : 0.005582\n",
      "           total : 0.016197\n",
      "-----------------------------------\n",
      "2023-01-07 00:26:38    Mean corner error is 16.856743\n",
      "2023-01-07 00:26:38    Acc using 5 px 2D Projection = 66.67%\n",
      "2023-01-07 00:26:38    Acc using 0.0109 vx 3D Transformation = 9.86%\n",
      "2023-01-07 00:26:38    Acc using 5 cm 5 degree metric = 6.95%\n",
      "2023-01-07 00:26:38    Translation error: 0.193004, angle error: 22.229305\n",
      "2023-01-07 00:26:38 save training stats to backup/duck/costs.npz\n",
      "2023-01-07 00:26:38 best model so far!\n",
      "2023-01-07 00:26:38 save weights to backup/duck/model.weights\n",
      "2023-01-07 00:27:36 EPOCH: [30/500]\n",
      "2023-01-07 00:27:36    Testing...\n",
      "2023-01-07 00:27:36    Number of test samples: 1065\n",
      "-----------------------------------\n",
      "  tensor to cuda : 0.000601\n",
      "         predict : 0.003558\n",
      "get_region_boxes : 0.005524\n",
      "            eval : 0.002472\n",
      "           total : 0.012155\n",
      "-----------------------------------\n",
      "2023-01-07 00:28:06    Mean corner error is 13.180949\n",
      "2023-01-07 00:28:06    Acc using 5 px 2D Projection = 73.62%\n",
      "2023-01-07 00:28:06    Acc using 0.0109 vx 3D Transformation = 9.58%\n",
      "2023-01-07 00:28:06    Acc using 5 cm 5 degree metric = 8.73%\n",
      "2023-01-07 00:28:06    Translation error: 0.128016, angle error: 17.038709\n",
      "2023-01-07 00:28:06 save training stats to backup/duck/costs.npz\n",
      "2023-01-07 00:28:06 best model so far!\n",
      "2023-01-07 00:28:06 save weights to backup/duck/model.weights\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(init_epoch, max_epochs): \n",
    "    # TRAIN\n",
    "    niter = train(epoch)\n",
    "    # TEST and SAVE\n",
    "    if (epoch % 10 == 0) and (epoch >= 15): \n",
    "        logging(f'EPOCH: [{epoch}/{max_epochs}]')\n",
    "        test(epoch, niter)\n",
    "        logging('save training stats to %s/costs.npz' % (backupdir))\n",
    "        np.savez(os.path.join(backupdir, \"costs.npz\"),\n",
    "            training_iters=training_iters,\n",
    "            training_losses=training_losses,\n",
    "            testing_iters=testing_iters,\n",
    "            testing_accuracies=testing_accuracies,\n",
    "            testing_errors_pixel=testing_errors_pixel,\n",
    "            testing_errors_angle=testing_errors_angle) \n",
    "        if (testing_accuracies[-1] > best_acc):\n",
    "            best_acc = testing_accuracies[-1]\n",
    "            logging('best model so far!')\n",
    "            logging('save weights to %s/model.weights' % (backupdir))\n",
    "            model.save_weights('%s/model.weights' % (backupdir))\n",
    "# shutil.copy2('%s/model.weights' % (backupdir), '%s/model_backup.weights' % (backupdir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205b5188",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-04T14:30:34.345451Z",
     "start_time": "2023-01-04T14:30:34.345442Z"
    }
   },
   "outputs": [],
   "source": [
    "# !poweroff"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "c1c23a684b610eb4212e1950577c1fbeeeb38638a2c1436493e4fcd35c8aacc7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
